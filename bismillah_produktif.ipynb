{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGQJfrQtgXxr",
        "outputId": "6b3bad93-34e1-47cf-ba7a-3abae587c183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.6.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo pandas scikit-learn imbalanced-learn matplotlib seaborn\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN\n",
        "import xgboost as xgb\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import warning\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mengambil Dataset AI4I 2020 Predictive Maintenance.\")\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "ai4i_2020_predictive_maintenance_dataset = fetch_ucirepo(id=601)\n",
        "\n",
        "X = ai4i_2020_predictive_maintenance_dataset.data.features\n",
        "y_raw = ai4i_2020_predictive_maintenance_dataset.data.targets\n",
        "\n",
        "try:\n",
        "    y = y_raw['Target']\n",
        "except KeyError:\n",
        "    print(\"\\nPeringatan: Kolom 'Target' tidak ditemukan. Mencoba menggunakan kolom pertama dari targets sebagai default.\")\n",
        "    y = y_raw.iloc[:, 0]\n",
        "    print(f\"Menggunakan kolom '{y.name}' sebagai target.\")"
      ],
      "metadata": {
        "id": "Xdy3mQ2n4Hm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metadata Dataset:\")\n",
        "print(ai4i_2020_predictive_maintenance_dataset.metadata)\n",
        "\n",
        "print(\"\\nInformasi Variabel Dataset (ai4i_2020_predictive_maintenance_dataset.variables):\")\n",
        "print(ai4i_2020_predictive_maintenance_dataset.variables)\n",
        "\n",
        "if 'Product ID' in X.columns:\n",
        "    X = X.drop('Product ID', axis=1)\n",
        "\n",
        "numerical_cols = ai4i_2020_predictive_maintenance_dataset.variables[\n",
        "    (ai4i_2020_predictive_maintenance_dataset.variables['type'] == 'Continuous') &\n",
        "    (ai4i_2020_predictive_maintenance_dataset.variables['name'] != 'Product ID')\n",
        "]['name'].tolist()\n",
        "\n",
        "categorical_cols = ai4i_2020_predictive_maintenance_dataset.variables[\n",
        "    (ai4i_2020_predictive_maintenance_dataset.variables['type'] == 'Categorical')\n",
        "]['name'].tolist()\n",
        "\n",
        "numerical_cols = [col for col in numerical_cols if col in X.columns]\n",
        "categorical_cols = [col for col in categorical_cols if col in X.columns]\n",
        "\n",
        "print(\"Kolom Numerik yang Diidentifikasi Secara Otomatis:\")\n",
        "print(numerical_cols)\n",
        "print(\"Kolom Kategorikal yang Diidentifikasi Secara Otomatis:\")\n",
        "print(categorical_cols)"
      ],
      "metadata": {
        "id": "8hUN3_uE4Vdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Eksplorasi Data Awal:\")\n",
        "print(\"Bentuk X:\", X.shape)\n",
        "print(\"Bentuk y:\", y.shape)\n",
        "print(\"\\nInfo X:\")\n",
        "X.info()\n",
        "\n",
        "print(\"\\nDistribusi kelas di variabel target 'Target':\")\n",
        "target_counts = Counter(y)\n",
        "total_samples = sum(target_counts.values())\n",
        "for label, count in target_counts.items():\n",
        "    percentage = (count / total_samples) * 100\n",
        "    print(f\"Kelas {label}: {count} sampel ({percentage:.2f}%)\")\n",
        "\n",
        "if 1 in target_counts and target_counts[1] < target_counts[0] / 5:\n",
        "    print(\"\\nDataset kemungkinan mengalami **ketidakseimbangan (imbalance)** yang signifikan. Penanganan imbalance (seperti SMOTE) kemungkinan besar diperlukan.\")\n",
        "else:\n",
        "    print(\"\\nDataset terlihat cukup seimbang atau ketidakseimbangan tidak terlalu parah.\")\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=y)\n",
        "plt.title('Distribusi Kelas Target (Kegagalan Mesin)')\n",
        "plt.xlabel('Kegagalan (0: Tidak, 1: Ya)')\n",
        "plt.ylabel('Jumlah Sampel')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b3XBLq0P4cD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "s7ougYdQ6sge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")"
      ],
      "metadata": {
        "id": "DQovq5DX4k93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nJumlah sampel training sebelum resampling: {Counter(y_train)}\")"
      ],
      "metadata": {
        "id": "-eOqD-4S4hqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMelakukan Preprocessing Data.\")\n",
        "\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "processed_feature_names = []\n",
        "if 'num' in preprocessor.named_transformers_:\n",
        "    processed_feature_names.extend([f'num__{col}' for col in numerical_cols])\n",
        "if 'cat' in preprocessor.named_transformers_ and hasattr(preprocessor.named_transformers_['cat'], 'get_feature_names_out'):\n",
        "    processed_feature_names.extend(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols))\n",
        "\n",
        "remainder_features = [col for col in X.columns if col not in numerical_cols + categorical_cols + ['Product ID']]\n",
        "if 'remainder' in preprocessor.named_transformers_:\n",
        "    processed_feature_names.extend([f'remainder__{col}' for col in remainder_features])\n",
        "\n",
        "if len(processed_feature_names) != X_train_processed.shape[1]:\n",
        "    print(\"\\nPeringatan: Gagal mendapatkan semua nama fitur yang diproses secara otomatis. Menggunakan nama generik.\")\n",
        "    processed_feature_names = [f\"feature_{i}\" for i in range(X_train_processed.shape[1])]\n",
        "\n",
        "\n",
        "X_train_processed_df = pd.DataFrame(X_train_processed, columns=processed_feature_names)\n",
        "X_test_processed_df = pd.DataFrame(X_test_processed, columns=processed_feature_names)"
      ],
      "metadata": {
        "id": "xEac4OKS5HjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate_model"
      ],
      "metadata": {
        "id": "7xgV_aF_waOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name, feature_names, feature_descriptions_map):\n",
        "    \"\"\"\n",
        "    Melakukan prediksi dan evaluasi model, serta menampilkan feature importance.\n",
        "    \"\"\"\n",
        "    print(f\"\\nEvaluasi Model {model_name}:\")\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(\"\\nLaporan Klasifikasi:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Prediksi Non-Gagal', 'Prediksi Gagal'],\n",
        "                yticklabels=['Aktual Non-Gagal', 'Aktual Gagal'])\n",
        "    plt.title(f'Confusion Matrix ({model_name})')\n",
        "    plt.ylabel('Aktual')\n",
        "    plt.xlabel('Prediksi')\n",
        "    plt.show()\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "    print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
        "\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    print(f\"Precision-Recall AUC: {pr_auc:.4f}\")\n",
        "\n",
        "    print(f\"\\nAnalisis Feature Importance ({model_name}):\")\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        feature_importances = pd.Series(model.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
        "    elif hasattr(model, 'coef_'):\n",
        "        if model.coef_.ndim > 1:\n",
        "            feature_importances = pd.Series(np.abs(model.coef_[0]), index=feature_names).sort_values(ascending=False)\n",
        "        else:\n",
        "            feature_importances = pd.Series(np.abs(model.coef_), index=feature_names).sort_values(ascending=False)\n",
        "    else:\n",
        "        print(\"Model tidak memiliki atribut feature_importances_ atau coef_.\")\n",
        "        return\n",
        "\n",
        "    readable_feature_importances = []\n",
        "    for feature, importance in feature_importances.items():\n",
        "        original_name = feature.split('__')[-1]\n",
        "        display_name = feature_descriptions_map.get(original_name, original_name)\n",
        "        readable_feature_importances.append(f\"{feature} ({display_name}): {importance:.6f}\")\n",
        "\n",
        "    for line in readable_feature_importances:\n",
        "        print(line)\n",
        "\n",
        "    plt.figure(figsize=(10, max(6, len(feature_importances) // 2)))\n",
        "    sns.barplot(x=feature_importances.values, y=feature_importances.index, palette='viridis')\n",
        "    plt.title(f'Feature Importance dari {model_name}')\n",
        "    plt.xlabel('Kepentingan')\n",
        "    plt.ylabel('Fitur')\n",
        "    plt.show()\n",
        "\n",
        "feature_descriptions = {\n",
        "    'Air temperature': 'Suhu Udara',\n",
        "    'Process temperature': 'Suhu Proses',\n",
        "    'Rotational speed': 'Kecepatan Rotasi',\n",
        "    'Torque': 'Torsi',\n",
        "    'Tool wear': 'Keausan Alat',\n",
        "    'Type_L': 'Tipe Produk (Rendah)',\n",
        "    'Type_M': 'Tipe Produk (Sedang)',\n",
        "    'Type_H': 'Tipe Produk (Tinggi)',\n",
        "}\n"
      ],
      "metadata": {
        "id": "N9Tdaokyvzs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resampling_methods = {\n",
        "    \"SMOTE\": SMOTE(random_state=42),\n",
        "    \"SMOTETomek\": SMOTETomek(random_state=42),\n",
        "    \"SMOTEENN\": SMOTEENN(random_state=42)\n",
        "}\n",
        "\n",
        "for method_name, resampler_instance in resampling_methods.items():\n",
        "    print(f\"\\n\\n{'='*60}\")\n",
        "    print(f\"      Melatih Model dengan Resampling: {method_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(f\"\\nMelakukan Resampling dengan {method_name}:\")\n",
        "    X_train_resampled, y_train_resampled = resampler_instance.fit_resample(X_train_processed_df, y_train)\n",
        "    print(f\"Jumlah sampel training setelah {method_name}: {Counter(y_train_resampled)}\")\n",
        "\n",
        "    print(f\"\\nMelatih Model Random Forest untuk {method_name}:\")\n",
        "    rf_model = RandomForestClassifier(random_state=42)\n",
        "    rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "    evaluate_model(rf_model, X_test_processed_df, y_test, f\"Random Forest ({method_name})\", processed_feature_names, feature_descriptions)\n",
        "\n",
        "    print(f\"\\nMelatih Model XGBoost untuk {method_name}:\")\n",
        "    xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
        "    xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "    evaluate_model(xgb_model, X_test_processed_df, y_test, f\"XGBoost ({method_name})\", processed_feature_names, feature_descriptions)\n",
        "\n",
        "print(\"\\n\\nProses pelatihan dan evaluasi untuk semua metode resampling selesai!\")"
      ],
      "metadata": {
        "id": "5wo9lx-fvzkZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}